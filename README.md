# NLP Training Lab (PyTorch)

Welcome! This repository is part of an educational series where I explore, document, and teach core NLP concepts using PyTorch — from foundational ideas like RNNs to more advanced topics like Transformers and LLM fine-tuning.

Each notebook is written with clarity and structure, meant to balance both practical understanding and professional code style. While some examples are minimal or toy-sized, the focus is on understanding why and how things work — a crucial step for mastering real-world NLP.

---

## 🧠 Folders Index

| Notebook                         | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| `01_pytorch_crashcourse`  | A beginner-friendly crash course in PyTorch, covering tensors, gradients, and simple models (including a custom `SimpleNet`) |
| `02_rnn`      | Toy RNN-based models for 3 NLP tasks (language modeling, tagging, classification) |
| `03_transformers`      | Examples to showcase multihead self-attention tensor calculations with positional encoding  |
| *More coming soon*              | Transformers, Attention, LLM Fine-Tuning, RAG, and more |

---

## 🔧 How to Use

You can run the notebooks in:
- Jupyter Notebook or JupyterLab
- Google Colab

No special data or GPU is required — all examples are self-contained and CPU-friendly.

---

## 💡 About This Project

> 💬 *“Reports of the death of programming are greatly exaggerated.”*  
> – Bill Gates (2024), on the future of software in the age of AI

Here, I break down complex NLP and LLM topics, implement core architectures, and share insights from my 4+ years of experience in data science, banking AI, and deep learning research.

I believe that:
- In an age where everyone is *using* AI, few truly *understand* it.
- Learning the internals of Transformers, attention, embeddings, and LLM pipelines is what sets great engineers apart.
- Clarity is power — and sharing that clarity makes the whole field stronger.

This repo is:
- 🧪 A space where I explore and document foundational and advanced concepts.
- 📚 A resource for those seeking hands-on, annotated PyTorch examples.
- 🧭 A reflection of my belief in **deep work**, **mathematical grounding**, and **real-world application**.

> 🧩 AI is not magic. It's math, logic, and engineering — and we *can* understand it.  
> If we want to shape the future, we need to know how the tools work — from the inside out.

Whether you're a fellow learner or someone getting lost in the sea of LLM buzzwords — I hope this repo helps you rediscover the beauty of clear thinking and clean code.



