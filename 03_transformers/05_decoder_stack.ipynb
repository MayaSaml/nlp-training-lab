{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59be89d-5a0e-4c4a-987f-1d8963adbbb0",
   "metadata": {},
   "source": [
    "# Full Transformer Decoder Stack\n",
    "Implements a full stack of **8 Transformer decoder blocks** using PyTorch.\n",
    "\n",
    "Each decoder block contains:\n",
    "- Masked Multi-Head Self-Attention (prevents peeking ahead)\n",
    "- Encoder–Decoder Attention (cross-attends to encoder output)\n",
    "- Residual connections + LayerNorm\n",
    "- Feedforward Network (512 → 2048 → 512)\n",
    "\n",
    "The decoder input (e.g. \"I understand this\") is treated as a partially generated sentence, passed along with simulated encoder output.\n",
    "\n",
    "Output: Final token representations of shape (3, 512) — enriched through 8 rounds of self-attention, cross-attention, and feedforward computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa451b66-e20a-4191-88d3-09faf776aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# ------------------------\n",
    "# Positional Encoding Class\n",
    "# ------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)                # (max_len, 1)\n",
    "        i = torch.arange(d_model).unsqueeze(0)                       # (1, d_model)\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model)\n",
    "        angle_rads = position * angle_rates\n",
    "\n",
    "        PE = torch.zeros_like(angle_rads)\n",
    "        PE[:, 0::2] = torch.sin(angle_rads[:, 0::2])\n",
    "        PE[:, 1::2] = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        self.register_buffer('PE', PE)  # Not trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.PE[:seq_len]\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Decoder Block\n",
    "# ------------------------\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8, ffn_hidden=2048):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # 1. Masked Self-Attention\n",
    "        self.W_Q_self = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_K_self = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_V_self = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "\n",
    "        # 2. Encoder–Decoder Cross Attention\n",
    "        self.W_Q_encdec = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_K_encdec = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_V_encdec = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 3. Feedforward Network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_hidden, d_model)\n",
    "        )\n",
    "\n",
    "        # 4. LayerNorms\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_output, look_ahead_mask=None):\n",
    "        # ------------------\n",
    "        # 1. Masked Self-Attention\n",
    "        # ------------------\n",
    "        heads = []\n",
    "        for i in range(self.num_heads):\n",
    "            Q = self.W_Q_self[i](x)\n",
    "            K = self.W_K_self[i](x)\n",
    "            V = self.W_V_self[i](x)\n",
    "\n",
    "            scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "            if look_ahead_mask is not None:\n",
    "                scores = scores.masked_fill(look_ahead_mask == 0, float('-inf'))\n",
    "\n",
    "            attn = F.softmax(scores, dim=-1)\n",
    "            Z = attn @ V\n",
    "            heads.append(Z)\n",
    "\n",
    "        concat = torch.cat(heads, dim=-1)\n",
    "        self_attn_out = self.W_O(concat)\n",
    "        x = self.norm1(x + self_attn_out)\n",
    "\n",
    "        # ------------------\n",
    "        # 2. Encoder–Decoder Attention\n",
    "        # ------------------\n",
    "        heads = []\n",
    "        for i in range(self.num_heads):\n",
    "            Q = self.W_Q_encdec[i](x)\n",
    "            K = self.W_K_encdec[i](encoder_output)\n",
    "            V = self.W_V_encdec[i](encoder_output)\n",
    "\n",
    "            scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "            attn = F.softmax(scores, dim=-1)\n",
    "            Z = attn @ V\n",
    "            heads.append(Z)\n",
    "\n",
    "        concat = torch.cat(heads, dim=-1)\n",
    "        encdec_out = self.W_O(concat)\n",
    "        x = self.norm2(x + encdec_out)\n",
    "\n",
    "        # ------------------\n",
    "        # 3. Feedforward\n",
    "        # ------------------\n",
    "        ffn_out = self.ffn(x)\n",
    "        out = self.norm3(x + ffn_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Decoder Stack\n",
    "# ------------------------\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, num_layers=8, d_model=512, num_heads=8, ffn_hidden=2048):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, ffn_hidden) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, encoder_output, look_ahead_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, look_ahead_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286b1940-4838-4191-85f1-5647ec95d707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_503</th>\n",
       "      <th>dim_504</th>\n",
       "      <th>dim_505</th>\n",
       "      <th>dim_506</th>\n",
       "      <th>dim_507</th>\n",
       "      <th>dim_508</th>\n",
       "      <th>dim_509</th>\n",
       "      <th>dim_510</th>\n",
       "      <th>dim_511</th>\n",
       "      <th>dim_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>-0.700927</td>\n",
       "      <td>0.459993</td>\n",
       "      <td>0.486396</td>\n",
       "      <td>-0.760917</td>\n",
       "      <td>-0.544988</td>\n",
       "      <td>0.681811</td>\n",
       "      <td>-0.704418</td>\n",
       "      <td>-0.278896</td>\n",
       "      <td>1.915847</td>\n",
       "      <td>-1.126197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>2.104369</td>\n",
       "      <td>-1.647549</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>-0.030985</td>\n",
       "      <td>0.555180</td>\n",
       "      <td>-1.075598</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.837795</td>\n",
       "      <td>0.963089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>0.454692</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>0.276973</td>\n",
       "      <td>-1.402326</td>\n",
       "      <td>1.036451</td>\n",
       "      <td>-1.022408</td>\n",
       "      <td>0.738934</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>0.364696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597994</td>\n",
       "      <td>1.023504</td>\n",
       "      <td>-2.176769</td>\n",
       "      <td>0.979234</td>\n",
       "      <td>-1.116079</td>\n",
       "      <td>1.496523</td>\n",
       "      <td>-2.329080</td>\n",
       "      <td>-1.127260</td>\n",
       "      <td>-0.072432</td>\n",
       "      <td>0.590817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>-0.536496</td>\n",
       "      <td>0.276218</td>\n",
       "      <td>-0.451541</td>\n",
       "      <td>-1.167974</td>\n",
       "      <td>-0.995088</td>\n",
       "      <td>0.064617</td>\n",
       "      <td>-1.456940</td>\n",
       "      <td>0.229347</td>\n",
       "      <td>1.807538</td>\n",
       "      <td>-0.631978</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278745</td>\n",
       "      <td>1.378657</td>\n",
       "      <td>-1.698918</td>\n",
       "      <td>0.066068</td>\n",
       "      <td>-0.491405</td>\n",
       "      <td>0.753732</td>\n",
       "      <td>-1.628311</td>\n",
       "      <td>-1.579115</td>\n",
       "      <td>0.411480</td>\n",
       "      <td>0.160179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "I          -0.700927  0.459993  0.486396 -0.760917 -0.544988  0.681811   \n",
       "understand  0.454692 -0.059841  0.121340  0.276973 -1.402326  1.036451   \n",
       "this       -0.536496  0.276218 -0.451541 -1.167974 -0.995088  0.064617   \n",
       "\n",
       "               dim_7     dim_8     dim_9    dim_10  ...   dim_503   dim_504  \\\n",
       "I          -0.704418 -0.278896  1.915847 -1.126197  ...  0.038788  2.104369   \n",
       "understand -1.022408  0.738934  0.494328  0.364696  ... -0.597994  1.023504   \n",
       "this       -1.456940  0.229347  1.807538 -0.631978  ... -1.278745  1.378657   \n",
       "\n",
       "             dim_505   dim_506   dim_507   dim_508   dim_509   dim_510  \\\n",
       "I          -1.647549  0.110661 -0.030985  0.555180 -1.075598  0.119225   \n",
       "understand -2.176769  0.979234 -1.116079  1.496523 -2.329080 -1.127260   \n",
       "this       -1.698918  0.066068 -0.491405  0.753732 -1.628311 -1.579115   \n",
       "\n",
       "             dim_511   dim_512  \n",
       "I          -0.837795  0.963089  \n",
       "understand -0.072432  0.590817  \n",
       "this        0.411480  0.160179  \n",
       "\n",
       "[3 rows x 512 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Example Usage\n",
    "# ------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Toy sentence (pretend it's the decoder input so far)\n",
    "decoder_tokens = [\"I\", \"understand\", \"this\"]\n",
    "seq_len = len(decoder_tokens)\n",
    "d_model = 512\n",
    "\n",
    "# Random decoder embeddings\n",
    "decoder_input = torch.randn(seq_len, d_model)\n",
    "\n",
    "# Add positional encoding\n",
    "pe = PositionalEncoding(d_model)\n",
    "decoder_input = pe(decoder_input)\n",
    "\n",
    "# Simulated encoder output (normally comes from encoder block)\n",
    "encoder_output = torch.randn(seq_len, d_model)\n",
    "\n",
    "# Look-ahead mask (prevents future peeking in decoder self-attn)\n",
    "look_ahead_mask = torch.tril(torch.ones(seq_len, seq_len)).bool()\n",
    "\n",
    "# Build decoder stack\n",
    "decoder = TransformerDecoder(num_layers=8)\n",
    "\n",
    "# Run decoder\n",
    "decoder_output = decoder(decoder_input, encoder_output, look_ahead_mask)\n",
    "\n",
    "# Inspect result\n",
    "df = pd.DataFrame(decoder_output.detach().numpy(), index=decoder_tokens, columns=[f\"dim_{i+1}\" for i in range(d_model)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f0730-dd8b-4800-a173-02de338cab03",
   "metadata": {},
   "source": [
    "### * Note on Real Use Case\n",
    "In a real translation task, here's what will happen:\n",
    "- encoder_output will come from passing the source sentence through the encoder.\n",
    "- decoder_input will be the target sentence, but shifted right (starting with a special token indicating the beginning of sentence) — this is called teacher forcing.\n",
    "- The model is trained to predict the next word at each position.\n",
    "- Look-ahead masking ensures that the model doesn't cheat by peeking into the future.\n",
    "\n",
    "Right now we just use random vectors to test the architecture. Later, we’ll hook it to real tokens, embeddings, vocabulary, and training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d0ef5a-39a2-41e1-9b30-5fd77c4fdba4",
   "metadata": {},
   "source": [
    "# Transformer Decoder Block — Shapes, Concepts & Flow\n",
    "\n",
    "### Decoder Input Embedding (with Positional Encoding)\n",
    "\n",
    "| Step | Name                | Shape                 | Description                                  |\n",
    "|------|---------------------|------------------------|----------------------------------------------|\n",
    "| 1    | Decoder Input `x`   | `(seq_len, d_model)`   | Input embeddings (e.g. previous target tokens) |\n",
    "| 2    | Positional Encoding | `(seq_len, d_model)`   | Adds timing information using sin/cos waves  |\n",
    "| 3    | Input + PE          | `(seq_len, d_model)`   | Final input to decoder stack                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Masked Multi-Head Self-Attention (per decoder layer)\n",
    "\n",
    "| Step | Name               | Shape                     | Description                                          |\n",
    "|------|--------------------|----------------------------|------------------------------------------------------|\n",
    "| 4    | Linear Q/K/V       | `(seq_len, d_k)`           | Projects input into queries, keys, and values        |\n",
    "| 5    | Attention Scores   | `(seq_len, seq_len)`       | Dot product of Q and Kᵀ, scaled                     |\n",
    "| 6    | Look-Ahead Mask    | `(seq_len, seq_len)`       | Masks out future positions during training          |\n",
    "| 7    | Weighted V         | `(seq_len, d_k)`           | Attention-weighted sum of values                    |\n",
    "| 8    | Heads              | `num_heads × (seq_len, d_k)` | Separate attention heads                         |\n",
    "| 9    | Concatenation      | `(seq_len, d_model)`       | Merge all heads                                     |\n",
    "| 10   | Final Linear       | `(seq_len, d_model)`       | Project back to full model dimension                |\n",
    "| 11   | Add & Norm1        | `(seq_len, d_model)`       | Residual + LayerNorm                                |\n",
    "\n",
    "---\n",
    "\n",
    "### Encoder–Decoder Cross Attention\n",
    "\n",
    "| Step | Name                 | Shape                     | Description                                             |\n",
    "|------|----------------------|----------------------------|---------------------------------------------------------|\n",
    "| 12   | Linear Q (from Dec)  | `(seq_len, d_k)`           | Queries from decoder                                    |\n",
    "| 13   | Linear K/V (from Enc)| `(seq_len, d_k)`           | Keys and values from encoder output                     |\n",
    "| 14   | Cross-Attn Scores    | `(seq_len, seq_len)`       | Dot product between decoder queries and encoder keys    |\n",
    "| 15   | Weighted V (Encoder) | `(seq_len, d_k)`           | Aggregated info from encoder                           |\n",
    "| 16   | Merge Heads          | `(seq_len, d_model)`       | Combine all heads                                       |\n",
    "| 17   | Final Linear         | `(seq_len, d_model)`       | Project to model dim                                    |\n",
    "| 18   | Add & Norm2          | `(seq_len, d_model)`       | Residual + LayerNorm                                    |\n",
    "\n",
    "---\n",
    "\n",
    "### Feedforward Network\n",
    "\n",
    "| Step | Name          | Shape                   | Description                                  |\n",
    "|------|---------------|--------------------------|----------------------------------------------|\n",
    "| 19   | Linear 1      | `(seq_len, ffn_hidden)`  | Expands representation (e.g., 512 → 2048)    |\n",
    "| 20   | ReLU          | `(seq_len, ffn_hidden)`  | Non-linearity                                |\n",
    "| 21   | Linear 2      | `(seq_len, d_model)`     | Project back to model dimension              |\n",
    "| 22   | Add & Norm3   | `(seq_len, d_model)`     | Final residual + LayerNorm                   |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts Recap\n",
    "\n",
    "- **Masked Self-Attention:** Allows each position to only attend to past (and current) tokens — essential for autoregressive decoding.\n",
    "- **Cross-Attention:** Each target token attends to all source (encoder) tokens — brings in source-side context.\n",
    "- **Multi-Head Attention:** Enables learning from multiple representation subspaces.\n",
    "- **LayerNorm & Residuals:** Ensure training stability and gradient flow.\n",
    "- **FFN:** Adds non-linearity and dimensional transformation for token-wise refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42ba76-499c-4b85-a5f8-27d02d7ab1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp",
   "language": "python",
   "name": "gcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
