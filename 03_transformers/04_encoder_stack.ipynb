{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac4953e-cc1c-4ae4-96d2-b645b19928ea",
   "metadata": {},
   "source": [
    "# Full Transformer Encoder Stack\n",
    "\n",
    "Implements a full stack of **8 Transformer encoder blocks** using PyTorch.\n",
    "\n",
    "Each block consists of:\n",
    "- Multi-head self-attention (8 heads, d_k = 64)\n",
    "- Residual connections + LayerNorm\n",
    "- Feedforward network (512 → 2048 → 512)\n",
    "\n",
    "The sentence `\"I understand this\"` is passed through the stack, starting with random embeddings and sinusoidal positional encoding.\n",
    "\n",
    "Output: Final token representations of shape `(3, 512)` — enriched by 8 rounds of context-aware attention and feedforward refinement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e1d23b-a746-45b1-b718-02958393e22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_503</th>\n",
       "      <th>dim_504</th>\n",
       "      <th>dim_505</th>\n",
       "      <th>dim_506</th>\n",
       "      <th>dim_507</th>\n",
       "      <th>dim_508</th>\n",
       "      <th>dim_509</th>\n",
       "      <th>dim_510</th>\n",
       "      <th>dim_511</th>\n",
       "      <th>dim_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.409755</td>\n",
       "      <td>1.064533</td>\n",
       "      <td>-1.274363</td>\n",
       "      <td>0.566124</td>\n",
       "      <td>-0.661616</td>\n",
       "      <td>0.563500</td>\n",
       "      <td>-1.181764</td>\n",
       "      <td>1.042684</td>\n",
       "      <td>-0.721654</td>\n",
       "      <td>0.103133</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.375124</td>\n",
       "      <td>0.153936</td>\n",
       "      <td>0.144869</td>\n",
       "      <td>2.302020</td>\n",
       "      <td>0.333517</td>\n",
       "      <td>0.193574</td>\n",
       "      <td>-0.723363</td>\n",
       "      <td>1.025196</td>\n",
       "      <td>-1.732543</td>\n",
       "      <td>1.695154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>0.330104</td>\n",
       "      <td>-0.678932</td>\n",
       "      <td>-0.859399</td>\n",
       "      <td>0.669225</td>\n",
       "      <td>-1.591900</td>\n",
       "      <td>0.689216</td>\n",
       "      <td>1.414400</td>\n",
       "      <td>0.719710</td>\n",
       "      <td>-0.572838</td>\n",
       "      <td>-0.566850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922850</td>\n",
       "      <td>0.712886</td>\n",
       "      <td>-1.397764</td>\n",
       "      <td>1.799990</td>\n",
       "      <td>-1.423614</td>\n",
       "      <td>-0.714672</td>\n",
       "      <td>0.450547</td>\n",
       "      <td>0.620331</td>\n",
       "      <td>-1.431469</td>\n",
       "      <td>0.726397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.344423</td>\n",
       "      <td>-0.937808</td>\n",
       "      <td>-0.232735</td>\n",
       "      <td>-0.530076</td>\n",
       "      <td>-0.609216</td>\n",
       "      <td>-0.165748</td>\n",
       "      <td>0.861662</td>\n",
       "      <td>0.721980</td>\n",
       "      <td>-0.208119</td>\n",
       "      <td>-0.853094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432759</td>\n",
       "      <td>0.786077</td>\n",
       "      <td>-0.697392</td>\n",
       "      <td>2.608974</td>\n",
       "      <td>-1.162237</td>\n",
       "      <td>-0.848736</td>\n",
       "      <td>0.440565</td>\n",
       "      <td>0.761107</td>\n",
       "      <td>-0.887701</td>\n",
       "      <td>0.315352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "I           0.409755  1.064533 -1.274363  0.566124 -0.661616  0.563500   \n",
       "understand  0.330104 -0.678932 -0.859399  0.669225 -1.591900  0.689216   \n",
       "this        0.344423 -0.937808 -0.232735 -0.530076 -0.609216 -0.165748   \n",
       "\n",
       "               dim_7     dim_8     dim_9    dim_10  ...   dim_503   dim_504  \\\n",
       "I          -1.181764  1.042684 -0.721654  0.103133  ... -1.375124  0.153936   \n",
       "understand  1.414400  0.719710 -0.572838 -0.566850  ... -0.922850  0.712886   \n",
       "this        0.861662  0.721980 -0.208119 -0.853094  ... -0.432759  0.786077   \n",
       "\n",
       "             dim_505   dim_506   dim_507   dim_508   dim_509   dim_510  \\\n",
       "I           0.144869  2.302020  0.333517  0.193574 -0.723363  1.025196   \n",
       "understand -1.397764  1.799990 -1.423614 -0.714672  0.450547  0.620331   \n",
       "this       -0.697392  2.608974 -1.162237 -0.848736  0.440565  0.761107   \n",
       "\n",
       "             dim_511   dim_512  \n",
       "I          -1.732543  1.695154  \n",
       "understand -1.431469  0.726397  \n",
       "this       -0.887701  0.315352  \n",
       "\n",
       "[3 rows x 512 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------\n",
    "# Positional Encoding Class\n",
    "# ------------------------\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        # Precompute positional encodings\n",
    "        position = torch.arange(max_len).unsqueeze(1)                  # (max_len, 1)\n",
    "        i = torch.arange(d_model).unsqueeze(0)                         # (1, d_model)\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model)   # (1, d_model)\n",
    "        angle_rads = position * angle_rates                            # (max_len, d_model)\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        PE = torch.zeros_like(angle_rads)\n",
    "        PE[:, 0::2] = torch.sin(angle_rads[:, 0::2])\n",
    "        PE[:, 1::2] = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        self.register_buffer('PE', PE)  # Register as buffer so it's saved with model but not trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Add positional encoding to input.\n",
    "        x: (seq_len, d_model)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.PE[:seq_len]\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Encoder Block: One Layer of Transformer Encoder\n",
    "# ------------------------\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8, ffn_hidden=2048):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads  # Each head gets d_model / num_heads dims\n",
    "\n",
    "        # Linear projections for Q, K, V for each head\n",
    "        self.W_Q = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_K = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "        self.W_V = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(num_heads)])\n",
    "\n",
    "        # Output projection (applied after concatenating heads)\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Position-wise Feedforward Network (2-layer MLP with ReLU)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),  # First layer expands\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_hidden, d_model)   # Second layer compresses back to d_model\n",
    "        )\n",
    "\n",
    "        # Layer Normalization (applied after each residual)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input of shape (seq_len, d_model)\n",
    "        Returns: Output of shape (seq_len, d_model)\n",
    "        \"\"\"\n",
    "        heads = []\n",
    "\n",
    "        # --- Multi-Head Self-Attention ---\n",
    "        for i in range(self.num_heads):\n",
    "            Q = self.W_Q[i](x)  # Shape: (seq_len, d_k)\n",
    "            K = self.W_K[i](x)\n",
    "            V = self.W_V[i](x)\n",
    "\n",
    "            # Scaled dot-product attention\n",
    "            scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)  # Shape: (seq_len, seq_len)\n",
    "            attn = F.softmax(scores, dim=-1)\n",
    "            Z = attn @ V  # Shape: (seq_len, d_k)\n",
    "\n",
    "            heads.append(Z)\n",
    "\n",
    "        # Concatenate attention heads → (seq_len, d_model)\n",
    "        concat = torch.cat(heads, dim=-1)\n",
    "\n",
    "        # Final projection to combine heads\n",
    "        attn_out = self.W_O(concat)\n",
    "\n",
    "        # Residual connection + LayerNorm\n",
    "        x = self.norm1(x + attn_out)\n",
    "\n",
    "        # --- Feedforward Sub-layer ---\n",
    "        ffn_out = self.ffn(x)            # Shape: (seq_len, d_model)\n",
    "        out = self.norm2(x + ffn_out)    # Residual + Norm again\n",
    "\n",
    "        return out  # Final output of one encoder layer\n",
    "\n",
    "# ------------------------\n",
    "# Transformer Encoder Stack\n",
    "# ------------------------\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, num_layers=8, d_model=512, num_heads=8, ffn_hidden=2048):\n",
    "        super().__init__()\n",
    "        # Stack N encoder blocks (each has its own weights)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, ffn_hidden) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass input x through all encoder blocks sequentially.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------\n",
    "# Example Usage\n",
    "# ------------------------\n",
    "\n",
    "# Our toy sentence\n",
    "tokens = [\"I\", \"understand\", \"this\"]\n",
    "seq_len = len(tokens)\n",
    "d_model = 512\n",
    "\n",
    "# Simulate embeddings (e.g., from an embedding layer or word2vec)\n",
    "X = torch.randn(seq_len, d_model)  # Shape: (3, 512)\n",
    "\n",
    "# Add positional encoding to embeddings\n",
    "pe = PositionalEncoding(d_model)\n",
    "X = pe(X)\n",
    "\n",
    "# Create Transformer encoder with 8 layers\n",
    "encoder = TransformerEncoder(num_layers=8)\n",
    "\n",
    "# Run the input through encoder\n",
    "encoder_output = encoder(X)  # Final shape: (3, 512)\n",
    "\n",
    "# Wrap in DataFrame for easier inspection\n",
    "df = pd.DataFrame(\n",
    "    encoder_output.detach().numpy(),\n",
    "    index=tokens,\n",
    "    columns=[f\"dim_{i+1}\" for i in range(d_model)]\n",
    ")\n",
    "\n",
    "df.head()  # Show first few dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cc414-a487-4a4c-991c-1a4b81f8a23a",
   "metadata": {},
   "source": [
    "# Transformer Encoder Block — Shapes, Concepts & Flow\n",
    "\n",
    "---\n",
    "\n",
    "### Input Embedding (with Positional Encoding)\n",
    "\n",
    "| Step | Name                | Shape                 | Description                                |\n",
    "|------|---------------------|------------------------|--------------------------------------------|\n",
    "| 1    | Input X             | `(seq_len, d_model)`   | Raw token embeddings                       |\n",
    "| 2    | Positional Encoding | `(seq_len, d_model)`   | Injects order info with sin/cos patterns   |\n",
    "| 3    | Input + PE          | `(seq_len, d_model)`   | Final input to encoder layers              |\n",
    "\n",
    "---\n",
    "\n",
    "### Multi-Head Self-Attention (per layer)\n",
    "\n",
    "| Step | Name             | Shape                     | Description                                 |\n",
    "|------|------------------|----------------------------|---------------------------------------------|\n",
    "| 4    | Linear Q/K/V     | `(seq_len, d_k)`           | Projects input into queries, keys, values   |\n",
    "| 5    | Attention Scores | `(seq_len, seq_len)`       | Compare each token to every other token     |\n",
    "| 6    | Weighted V       | `(seq_len, d_k)`           | Weighted average of values                  |\n",
    "| 7    | Heads            | `num_heads × (seq_len, d_k)` | Multiple attention views                 |\n",
    "| 8    | Concatenation    | `(seq_len, d_model)`       | Merge all heads                             |\n",
    "| 9    | Final Linear     | `(seq_len, d_model)`       | Mix info across all heads                   |\n",
    "\n",
    "---\n",
    "\n",
    "### Residual + LayerNorm\n",
    "\n",
    "| Step | Name        | Shape               | Description                                 |\n",
    "|------|-------------|---------------------|---------------------------------------------|\n",
    "| 10   | Add & Norm1 | `(seq_len, d_model)`| Stabilize + retain original signal          |\n",
    "\n",
    "---\n",
    "\n",
    "### Feedforward Network\n",
    "\n",
    "| Step | Name          | Shape                   | Description                                 |\n",
    "|------|---------------|--------------------------|---------------------------------------------|\n",
    "| 11   | Linear 1      | `(seq_len, ffn_hidden)`  | Expands representation space                |\n",
    "| 12   | ReLU          | `(seq_len, ffn_hidden)`  | Non-linear activation                       |\n",
    "| 13   | Linear 2      | `(seq_len, d_model)`     | Projects back to model dimension            |\n",
    "| 14   | Add & Norm2   | `(seq_len, d_model)`     | Final residual + normalization              |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts Recap\n",
    "\n",
    "- **Self-Attention:** Lets each token attend to every other token in the sequence.\n",
    "- **Multi-Head Attention:** Offers multiple \"views\" or representation subspaces.\n",
    "- **Positional Encoding:** Injects position awareness using sin/cos functions.\n",
    "- **Residual Connections:** Help preserve gradients and ease optimization.\n",
    "- **LayerNorm:** Normalizes across feature dimensions for stable learning.\n",
    "- **Feedforward Network:** Adds depth and non-linearity to each token's representation.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0e4aa-f1cc-4e45-870a-e95973e160b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp",
   "language": "python",
   "name": "gcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
